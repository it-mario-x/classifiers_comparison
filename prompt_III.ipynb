{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data represent 17 campaigns. They took place between May 2008 and November 2010. All this represent 79354 contacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn import set_config\n",
    "from sklearn.svm import SVC\n",
    "set_config(\"figure\")\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_camp = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_camp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According tho the description provided, we can see that the values representing missing values, per each column, are:\n",
    "\n",
    "- job : unknown\n",
    "- marital : unknown\n",
    "- education: unknown\n",
    "- default: unknown\n",
    "- housing: unknown\n",
    "- loan: unknown\n",
    "- poutcome: nonexistent\n",
    "\n",
    "\n",
    "Besides, some of the data that can be coerced to a different data type are:\n",
    "\n",
    "- housing and loan\n",
    "- month and day_of_week\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Business Objective is to compare the performance of the following classifiers:\n",
    "\n",
    "- K Nearest Neighbor\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_full_camp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice also that there are not null values. Nevertheless, as we have noticed before, some of the values are \"unknown\". We will proceed with the dataset as it is since unknown can represent a value to take into account for making business decision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features (columns 1 - 7), prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_bank = list(df_full_camp.columns[0:7])\n",
    "df_bank = pd.concat([df_full_camp[cols_bank],\n",
    "                     df_full_camp[['y']]\n",
    "                    ], \n",
    "                    axis=1\n",
    "                   ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan   y\n",
       "0   56  housemaid  married     basic.4y       no      no   no  no\n",
       "1   57   services  married  high.school  unknown      no   no  no\n",
       "2   37   services  married  high.school       no     yes   no  no\n",
       "3   40     admin.  married     basic.6y       no      no   no  no\n",
       "4   56   services  married  high.school       no      no  yes  no"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        41188 non-null  int64 \n",
      " 1   job        41188 non-null  object\n",
      " 2   marital    41188 non-null  object\n",
      " 3   education  41188 non-null  object\n",
      " 4   default    41188 non-null  object\n",
      " 5   housing    41188 non-null  object\n",
      " 6   loan       41188 non-null  object\n",
      " 7   y          41188 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_bank.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that one column is integer (age). All the rest are of type object.\n",
    "\n",
    "Let's have a look on the different values contained in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in the column AGE: \n",
      "[17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n",
      " 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64\n",
      " 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88\n",
      " 89 91 92 94 95 98]\n",
      "\n",
      "\n",
      "unique values in the column JOB: \n",
      "['housemaid' 'services' 'admin.' 'blue-collar' 'technician' 'retired'\n",
      " 'management' 'unemployed' 'self-employed' 'unknown' 'entrepreneur'\n",
      " 'student']\n",
      "\n",
      "\n",
      "unique values in the column MARITAL: \n",
      "['married' 'single' 'divorced' 'unknown']\n",
      "\n",
      "\n",
      "unique values in the column EDUCATION: \n",
      "['basic.4y' 'high.school' 'basic.6y' 'basic.9y' 'professional.course'\n",
      " 'unknown' 'university.degree' 'illiterate']\n",
      "\n",
      "\n",
      "unique values in the column DEFAULT: \n",
      "['no' 'unknown' 'yes']\n",
      "\n",
      "\n",
      "unique values in the column HOUSING: \n",
      "['no' 'yes' 'unknown']\n",
      "\n",
      "\n",
      "unique values in the column LOAN: \n",
      "['no' 'yes' 'unknown']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('unique values in the column AGE: '),print(np.sort(df_bank['age'].unique())),print('\\n')\n",
    "print('unique values in the column JOB: '),print(df_bank['job'].unique()),print('\\n')\n",
    "print('unique values in the column MARITAL: '),print(df_bank['marital'].unique()),print('\\n')\n",
    "print('unique values in the column EDUCATION: '),print(df_bank['education'].unique()),print('\\n')\n",
    "print('unique values in the column DEFAULT: '),print(df_bank['default'].unique()),print('\\n')\n",
    "print('unique values in the column HOUSING: '),print(df_bank['housing'].unique()),print('\\n')\n",
    "print('unique values in the column LOAN: '),print(df_bank['loan'].unique()),print('\\n');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation of tansformation and encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most of the columns are categorical, we will use a OneHotEncoder for all the columsn but the age which is numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_column_transformer((OneHotEncoder(drop = 'if_binary'), \n",
    "                                       ['job','marital','education','default','housing','loan']\n",
    "                                      ), \n",
    "                                     remainder = StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features and target preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bank.drop(columns=['y'], axis = 1)\n",
    "y = df_bank['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline of our model should be, for the 'no' answer, about **88.7%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873458288821987"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['y'].value_counts(normalize = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.1s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 ColumnTransformer(remainder=StandardScaler(),\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                  ['job', 'marital',\n",
       "                                                   'education', 'default',\n",
       "                                                   'housing', 'loan'])])),\n",
       "                ('lr', LogisticRegression(max_iter=1000, random_state=42))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logireg_pipe = Pipeline([('transform', transformer),\n",
    "                         ('lr', LogisticRegression(random_state=42,\n",
    "                                                   max_iter = 1000\n",
    "                                                   )\n",
    "                          )\n",
    "                         ],\n",
    "                         verbose=True\n",
    "                        )\n",
    "\n",
    "\n",
    "logireg_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "logireg_train_preds     = logireg_pipe.predict(X_train)\n",
    "logireg_test_preds     = logireg_pipe.predict(X_test)\n",
    "\n",
    "logireg_train_accuracy  = accuracy_score(y_train, logireg_train_preds)\n",
    "logireg_test_accuracy  = accuracy_score(y_test, logireg_test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Logistic Regresion model is for the train  set: **88.71%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887119225664433"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logireg_train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Logistic Regresion model is for the test set: **88.80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8880256385354958"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logireg_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN algorithm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 ColumnTransformer(remainder=StandardScaler(),\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                  ['job', 'marital',\n",
       "                                                   'education', 'default',\n",
       "                                                   'housing', 'loan'])])),\n",
       "                ('knn', KNeighborsClassifier())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipe = Pipeline([('transform', transformer),\n",
    "                     ('knn', KNeighborsClassifier())\n",
    "                    ],\n",
    "                    verbose=True\n",
    "                   )\n",
    "\n",
    "\n",
    "knn_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_preds     = knn_pipe.predict(X_train)\n",
    "knn_test_preds     = knn_pipe.predict(X_test)\n",
    "\n",
    "knn_train_accuracy  = accuracy_score(y_train, knn_train_preds)\n",
    "knn_test_accuracy  = accuracy_score(y_test, knn_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the K Nearest Neighbours model is for the train set: **89.05%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8905506458191706"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the K Nearest Neighbours model is for the test set: **87.66%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8766631057589589"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 ColumnTransformer(remainder=StandardScaler(),\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                  ['job', 'marital',\n",
       "                                                   'education', 'default',\n",
       "                                                   'housing', 'loan'])])),\n",
       "                ('tree', DecisionTreeClassifier())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_pipe = Pipeline([('transform', transformer),\n",
    "                      ('tree', DecisionTreeClassifier())\n",
    "                     ],\n",
    "                     verbose=True\n",
    "                    )\n",
    "\n",
    "\n",
    "tree_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_preds     = tree_pipe.predict(X_train)\n",
    "tree_test_preds     = tree_pipe.predict(X_test)\n",
    "\n",
    "tree_train_accuracy  = accuracy_score(y_train, tree_train_preds)\n",
    "tree_test_accuracy  = accuracy_score(y_test, tree_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Decision Tree model is for the train set: **91.69%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9169661066329999"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Decision Tree model is for the test set: **86.37%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647178789938818"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  38.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 ColumnTransformer(remainder=StandardScaler(),\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                  ['job', 'marital',\n",
       "                                                   'education', 'default',\n",
       "                                                   'housing', 'loan'])])),\n",
       "                ('svm', SVC())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipe = Pipeline([('transform', transformer),\n",
    "                     ('svm', SVC())\n",
    "                     ],\n",
    "                     verbose=True\n",
    "                    )\n",
    "\n",
    "\n",
    "svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_preds     = svm_pipe.predict(X_train)\n",
    "svm_test_preds     = svm_pipe.predict(X_test)\n",
    "\n",
    "svm_train_accuracy  = accuracy_score(y_train, svm_train_preds)\n",
    "svm_test_accuracy  = accuracy_score(y_test, svm_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Support Vector Machine model is for the train set: **88.74%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8874429445469554"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Support Vector Machine model is for the test set: **88.83%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8883169855297659"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.887119</td>\n",
       "      <td>0.888026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890551</td>\n",
       "      <td>0.876663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.916966</td>\n",
       "      <td>0.864718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.887443</td>\n",
       "      <td>0.888317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
       "0  Logistic Regression         0.2        0.887119       0.888026\n",
       "1                  KNN         0.0        0.890551       0.876663\n",
       "2        Decision Tree         0.4        0.916966       0.864718\n",
       "3                  SVM        37.7        0.887443       0.888317"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'Model':['Logistic Regression','KNN','Decision Tree','SVM'],\n",
    "                   'Train Time':[0.2,0.0,0.4,37.7],\n",
    "                   'Train Accuracy':[logireg_train_accuracy,knn_train_accuracy,tree_train_accuracy,svm_train_accuracy],\n",
    "                   'Test Accuracy':[logireg_test_accuracy,knn_test_accuracy,tree_test_accuracy,svm_test_accuracy]\n",
    "                  } \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('transform',\n",
       "                                        ColumnTransformer(remainder=StandardScaler(),\n",
       "                                                          transformers=[('onehotencoder',\n",
       "                                                                         OneHotEncoder(drop='if_binary'),\n",
       "                                                                         ['job',\n",
       "                                                                          'marital',\n",
       "                                                                          'education',\n",
       "                                                                          'default',\n",
       "                                                                          'housing',\n",
       "                                                                          'loan'])])),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=42))],\n",
       "                                verbose=True),\n",
       "             param_grid={'lr__C': array([0.01, 0.12, 0.23, 0.34, 0.45, 0.56, 0.67, 0.78, 0.89, 1.  ])})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logireg_params = {'lr__C': np.linspace(0.01,1,10)}\n",
    "\n",
    "logireg_grid = GridSearchCV(logireg_pipe, \n",
    "                            param_grid=logireg_params\n",
    "                           )\n",
    "logireg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "logireg_hyperp = list(logireg_grid.best_params_.values())[0]\n",
    "logireg_best_test_acc = logireg_grid.score(X_test, y_test)\n",
    "logireg_best_train_acc = logireg_grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Logistic Regression model for a Grid Search for the C hyperparameter is, for the train set: **88.71%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887119225664433"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logireg_best_train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Logistic Regression model for a Grid Search for the C hyperparameter is, for the test set: **88.80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8880256385354958"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logireg_best_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN algorithm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('transform',\n",
       "                                        ColumnTransformer(remainder=StandardScaler(),\n",
       "                                                          transformers=[('onehotencoder',\n",
       "                                                                         OneHotEncoder(drop='if_binary'),\n",
       "                                                                         ['job',\n",
       "                                                                          'marital',\n",
       "                                                                          'education',\n",
       "                                                                          'default',\n",
       "                                                                          'housing',\n",
       "                                                                          'loan'])])),\n",
       "                                       ('knn', KNeighborsClassifier())],\n",
       "                                verbose=True),\n",
       "             param_grid={'knn__n_neighbors': [5, 7, 10, 100, 1000]})"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_params = {'knn__n_neighbors': [5,7,10,100,1000]}\n",
    "\n",
    "knn_grid = GridSearchCV(knn_pipe, \n",
    "                        param_grid=knn_params\n",
    "                       )\n",
    "knn_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best_hyperp = list(knn_grid.best_params_.values())[0]\n",
    "knn_best_hyperp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_train_acc = knn_grid.score(X_train, y_train)\n",
    "knn_best_test_acc = knn_grid.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the KNN model for a Grid Search for the number of neighbours hyperparameter is, for the train set: **88.69%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869573662231718"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best_train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the KNN model for a Grid Search for the number of neighbours hyperparameter is, for the test set: **88.81%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8881227542002526"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 2) Processing tree, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('transform',\n",
       "                                        ColumnTransformer(remainder=StandardScaler(),\n",
       "                                                          transformers=[('onehotencoder',\n",
       "                                                                         OneHotEncoder(drop='if_binary'),\n",
       "                                                                         ['job',\n",
       "                                                                          'marital',\n",
       "                                                                          'education',\n",
       "                                                                          'default',\n",
       "                                                                          'housing',\n",
       "                                                                          'loan'])])),\n",
       "                                       ('tree', DecisionTreeClassifier())],\n",
       "                                verbose=True),\n",
       "             param_grid={'tree__max_depth': [1, 3, 5, 50, 100, 500]})"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_params = {'tree__max_depth': [1,3,5,50,100,500]}\n",
    "\n",
    "tree_grid = GridSearchCV(tree_pipe, \n",
    "                         param_grid=tree_params\n",
    "                       )\n",
    "tree_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_best_hyperp = list(tree_grid.best_params_.values())[0]\n",
    "tree_best_hyperp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_best_train_acc = tree_grid.score(X_train, y_train)\n",
    "tree_best_test_acc = tree_grid.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Decision Tree model for a Grid Search for the max depth hyperparameter is, for the train set: **88.71%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887119225664433"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_best_train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Decision Tree model for a Grid Search for the max depth hyperparameter is, for the train set: **88.80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8880256385354958"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_best_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  20.5s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.7s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.8s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  24.8s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  20.9s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.5s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.9s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.5s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.7s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.6s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  23.7s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.9s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.8s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  23.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  23.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  23.3s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  21.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  22.4s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svm, total=  39.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('transform',\n",
       "                                        ColumnTransformer(remainder=StandardScaler(),\n",
       "                                                          transformers=[('onehotencoder',\n",
       "                                                                         OneHotEncoder(drop='if_binary'),\n",
       "                                                                         ['job',\n",
       "                                                                          'marital',\n",
       "                                                                          'education',\n",
       "                                                                          'default',\n",
       "                                                                          'housing',\n",
       "                                                                          'loan'])])),\n",
       "                                       ('svm', SVC())],\n",
       "                                verbose=True),\n",
       "             param_grid={'svm__degree': [0, 1, 2, 3, 4, 5]})"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_params = {'svm__degree': [0,1,2,3,4,5]}\n",
    "\n",
    "svm_grid = GridSearchCV(svm_pipe, \n",
    "                        param_grid=svm_params\n",
    "                       )\n",
    "svm_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_best_hyperp = list(svm_grid.best_params_.values())[0]\n",
    "svm_best_hyperp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_best_train_acc = svm_grid.score(X_train, y_train)\n",
    "svm_best_test_acc = svm_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the SVM model for a Grid Search for the degree hyperparameter is, for the train set: **88.74%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8874429445469554"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_best_train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the SVM model for a Grid Search for the degree hyperparameter is, for the test set: **88.83%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8883169855297659"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_best_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Hyperparameter tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.887119</td>\n",
       "      <td>0.888026</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.888123</td>\n",
       "      <td>n_neighbors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.887119</td>\n",
       "      <td>0.888026</td>\n",
       "      <td>max_depth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.887443</td>\n",
       "      <td>0.888317</td>\n",
       "      <td>degree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Time  Train Accuracy  Test Accuracy  \\\n",
       "0  Logistic Regression         0.1        0.887119       0.888026   \n",
       "1                  KNN         0.0        0.886957       0.888123   \n",
       "2        Decision Tree         0.3        0.887119       0.888026   \n",
       "3                  SVM        21.7        0.887443       0.888317   \n",
       "\n",
       "  Hyperparameter tested  \n",
       "0                     C  \n",
       "1           n_neighbors  \n",
       "2             max_depth  \n",
       "3                degree  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'Model':['Logistic Regression','KNN','Decision Tree','SVM'],\n",
    "                   'Train Time':[0.1,0.0,0.3,21.7],\n",
    "                   'Train Accuracy':[logireg_best_train_acc,knn_best_train_acc,tree_best_train_acc,svm_best_train_acc],\n",
    "                   'Test Accuracy':[logireg_best_test_acc,knn_best_test_acc,tree_best_test_acc,svm_best_test_acc],\n",
    "                   'Hyperparameter tested':['C','n_neighbors','max_depth','degree']\n",
    "                  } \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusions, next steps  and further recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more accurate analysis, it could be possible to include more features to our analysis data set. Here, we have included just those related to the bank but could include much more. This would eventually increase the computational resources. \n",
    "\n",
    "But before including more features, we should wonder the added value to add them. For example, keeping the gender feature could be important if we thinkthat gender can have an impact on the result.\n",
    "\n",
    "For this analysis we have tuned some hyperparameter for each model, but we could tune more and for a wide range for a deeper analysis. \n",
    "\n",
    "In any case, we have seen that, after we tuned our models and we found out the best hyperparameter, the train and test accuracy time are decreased.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
